{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\NASA_PROJECT\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\NASA_PROJECT'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, y_train,X_test,y_test,models,param):\n",
    "    try:\n",
    "        report = {}\n",
    "\n",
    "        for i in range(len(list(models))):\n",
    "            model = list(models.values())[i]\n",
    "            para=param[list(models.keys())[i]]\n",
    "\n",
    "            gs = GridSearchCV(model,para,cv=3)\n",
    "            gs.fit(X_train,y_train) \n",
    "\n",
    "            model.set_params(**gs.best_params_)\n",
    "            model.fit(X_train,y_train)\n",
    "\n",
    "            #model.fit(X_train, y_train)  # Train model\n",
    "\n",
    "            y_train_pred = model.predict(X_train)\n",
    "\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            train_model_score = r2_score(y_train, y_train_pred)\n",
    "\n",
    "            test_model_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            report[list(models.keys())[i]] = test_model\n",
    "        \n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test, models,param):\n",
    "    try:\n",
    "        report = {} #Creating Dict report\n",
    "        logging.info(\"Creating model report\")\n",
    "        for i in range(len(models)):\n",
    "            model = list(models.values())[i] #Listed all models\n",
    "            logging.info(\"Model Listd in Dictionary\")\n",
    "            para=param[list(models.keys())[i]]\n",
    "            \n",
    "            \n",
    "            \n",
    "            gs = GridSearchCV(model,para,cv=3)\n",
    "            gs.fit(X_train,y_train)\n",
    "\n",
    "            model.set_params(**gs.best_params_)\n",
    "            model.fit(X_train,y_train)\n",
    "\n",
    "            logging.info(f\"{model} trained\")\n",
    "            \n",
    "            #Predicting value\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            logging.info(f\"{model} predicted\")\n",
    "            \n",
    "            #getting accuracy score\n",
    "            test_model_score = r2_score(y_test, y_test_pred)\n",
    "            logging.info(f\"{model} accuracy score generated\")\n",
    "            \n",
    "            report[list(models.keys())[i]] = test_model_score\n",
    "            logging.info(\"Report generated\")\n",
    "            \n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.info(\"Exception as model training step\")\n",
    "        raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(file_path, obj):\n",
    "    \n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        \n",
    "        os.makedirs(dir_path, exist_ok = True)\n",
    "        \n",
    "        with open(file_path, \"wb\") as file_obj:\n",
    "            pickle.dump(obj, file_obj)\n",
    "                   \n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    trained_model_file_path = os.path.join(\"artifacts\", \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model_trainer_config=ModelTrainerConfig()\n",
    "        \n",
    "    def initiate_model_training(self, train_array, test_array):\n",
    "        try:\n",
    "            #Separating Train & test array\n",
    "            X_train, y_train, X_test, y_test = (\n",
    "                train_array[:,:-1],\n",
    "                train_array[:, -1],\n",
    "                test_array[:, :-1],\n",
    "                test_array[:, -1]\n",
    "            )\n",
    "            \n",
    "            models = {\n",
    "                \n",
    "                \"LinearRegression\" : LinearRegression(),\n",
    "                \"SVR\" : SVR(),\n",
    "                \"RandomForest\" : RandomForestRegressor(),\n",
    "                \"KNN\" : KNeighborsRegressor(),\n",
    "                \"DecisionTree\" : DecisionTreeRegressor(),\n",
    "                \"GradientBoosting\" : GradientBoostingRegressor()\n",
    "            }\n",
    "            params = {\n",
    "                \n",
    "                \"LinearRegression\" : {},\n",
    "                \n",
    "                \"SVR\" : {\n",
    "                    # 'epsilon': [0.1, 0.2],\n",
    "                    # 'kernel': ['linear', 'poly'],\n",
    "                },\n",
    "                \n",
    "                \"RandomForest\" :{\n",
    "                    \n",
    "                    # 'criterion':['squared_error', 'absolute_error'],                 \n",
    "                    # 'max_features':['sqrt','log2'],\n",
    "                },\n",
    "                \n",
    "                \"KNN\" : {\n",
    "                    \n",
    "                    # 'n_neighbors' : [5, 7],\n",
    "                    # 'weights' : ['uniform', 'distance'],\n",
    "                },\n",
    "                 \"DecisionTree\" : {\n",
    "                    # 'criterion' : ['absolute_error', 'poisson'],\n",
    "                    # 'max_features':['sqrt','log2']\n",
    "                },\n",
    "                \n",
    "                \"GradientBoosting\" : {\n",
    "                    \n",
    "                    # 'loss':['squared_error', 'absolute_error'],\n",
    "                    # 'criterion':['squared_error', 'friedman_mse'],\n",
    "                }\n",
    "                \n",
    "                \n",
    "            }\n",
    "            \n",
    "            model_report:dict=evaluate_model(X_train, y_train, X_test, y_test, models,params)\n",
    "            print(model_report) \n",
    "            print(\"\\n**********\")\n",
    "            logging.info(f\"Model Report : {model_report}\")\n",
    "            \n",
    "            best_model_score = max(sorted(model_report.values()))\n",
    "            logging.info(\"Model score sorted\")\n",
    "            \n",
    "            #finding best model name\n",
    "            best_model_name = list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "            logging.info(\"Best model name has been found\")\n",
    "            \n",
    "            best_model = models[best_model_name]\n",
    "            print(f\"Best Model is {best_model_name} with accuracy : {best_model_score}\")\n",
    "            print(\"\\n*****\")\n",
    "            logging.info(f\"Best Model is {best_model_name} with accuracy : {best_model_score}\")\n",
    "            \n",
    "            save_object(   \n",
    "                file_path = self.model_trainer_config.trained_model_file_path, #storing file path\n",
    "                obj = best_model\n",
    "            )\n",
    "            logging.info(\"Best model saved as pkl file\")\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data_ingestion import DataIngestion\n",
    "from src.components.data_transformation import DataTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\NASA_PROJECT\\src\\utils.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_train = pd.read_sql_query(\"select * from train1\", mydb)\n",
      "c:\\NASA_PROJECT\\src\\utils.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_test = pd.read_sql_query(\"select * from test1\", mydb)\n",
      "c:\\NASA_PROJECT\\src\\components\\data_transformation.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"RUL\"][train_df[\"RUL\"] > 103] = 103\n",
      "c:\\NASA_PROJECT\\src\\components\\data_transformation.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"RUL\"][test_df[\"RUL\"] > 103] = 103\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data_ingestion = DataIngestion()\n",
    "    train_data, test_data = data_ingestion.initiate_data_ingestion()\n",
    "    \n",
    "    data_transformation = DataTransformation()\n",
    "    train_array, test_array = data_transformation.initiate_data_transformation(train_data, test_data)\n",
    "    \n",
    "    model_trainer = ModelTrainer()\n",
    "    model_trainer.initiate_model_training(train_array, test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
