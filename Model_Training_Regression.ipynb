{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603ff60",
   "metadata": {},
   "source": [
    "# First Dataset\n",
    "#### without dropping any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ddb78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('RawData/Train1_raw.csv')\n",
    "test1 = pd.read_csv('RawData/Test1_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding RUL(Remaining Useful Life)\n",
    "def categorize_zone(time_cycles, max_time_cycle):\n",
    "    time_percent = time_cycles / max_time_cycle\n",
    "    if time_percent <= 0.5:  \n",
    "        return \"Safe Zone\"\n",
    "    elif time_percent <= 0.8:\n",
    "        return \"Moderate Zone\"\n",
    "    else:\n",
    "        return \"Dangerous\"\n",
    "\n",
    "def add_zones_rul_column(df):\n",
    "    train_grouped_by_unit = df.groupby(by='engine_number') \n",
    "    max_time_cycles = train_grouped_by_unit['time_cycles'].max() \n",
    "    merged = df.merge(max_time_cycles.to_frame(name='max_time_cycle'), left_on='engine_number',right_index=True)\n",
    "    \n",
    "    merged[\"RUL\"] = merged[\"max_time_cycle\"] - merged['time_cycles']\n",
    "    \n",
    "    merged[\"zone\"] = merged.apply(lambda row: categorize_zone(row['time_cycles'], row['max_time_cycle']), axis=1)\n",
    "    \n",
    "    merged = merged.drop(\"max_time_cycle\", axis=1) \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_with_rul = add_zones_rul_column(train1)\n",
    "test1_with_rul = add_zones_rul_column(test1)\n",
    "train1_with_rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable for training\n",
    "features = train1_with_rul.drop(['RUL', 'zone'], axis=1)\n",
    "target = train1_with_rul['RUL']\n",
    "\n",
    "# for testing\n",
    "X_test = test1_with_rul.drop(['RUL', 'zone'], axis=1)\n",
    "y_test = test1_with_rul['RUL']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32427a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_val: \",X_val.shape)\n",
    "print(\"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of y_val: \",y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db08fdd",
   "metadata": {},
   "source": [
    "# ML Algo and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08799d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Lasso':Lasso(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "     'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'XGBRegressor': XGBRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    r2_square = r2_score(y_val, y_pred)\n",
    "    \n",
    "    # Check feature importances (for models that support it)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = model.feature_importances_\n",
    "    else:\n",
    "        feature_importances = None\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2_square,\n",
    "        'Feature_Importances': feature_importances\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bdaae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the linear regression model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Add the predictions to the test dataset\n",
    "test1_with_rul['Predicted_RUL'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_with_rul[test1_with_rul['engine_number'] == 2][['engine_number', 'time_cycles','RUL', 'Predicted_RUL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db79824",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[test1['engine_number'] == 2][['engine_number', 'time_cycles', 'Predicted_RUL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ee8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_with_rul[train1_with_rul['engine_number'] == 2][['engine_number', 'time_cycles', 'RUL']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5312c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1781e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad511ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7d304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529dc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc20d76b",
   "metadata": {},
   "source": [
    "# Divide data into target and features\n",
    "##### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('CleanedData/train1_clean.csv')\n",
    "test1 = pd.read_csv('CleanedData/test1_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ffa81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train1.drop(columns=['RUL','zone'],axis=1)\n",
    "y = train1['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910cc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sahpe of features: \", X.shape)\n",
    "print(\"Shape of target: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7197524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faee1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \",X_test.shape)\n",
    "print(\"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae050d0",
   "metadata": {},
   "source": [
    "## ML Algo and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01793a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Lasso':Lasso(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "     'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'XGBRegressor': XGBRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2_square = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Check feature importances (for models that support it)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = model.feature_importances_\n",
    "    else:\n",
    "        feature_importances = None\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2_square,\n",
    "        'Feature_Importances': feature_importances\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b95d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['engine_number', 'time_cycles', 'op_setting_1', 'op_setting_2',\n",
    "       'sensor_measurement2', 'sensor_measurement3', 'sensor_measurement4',\n",
    "       'sensor_measurement6', 'sensor_measurement7', 'sensor_measurement8',\n",
    "       'sensor_measurement9', 'sensor_measurement11', 'sensor_measurement12',\n",
    "       'sensor_measurement13', 'sensor_measurement15', 'sensor_measurement17',\n",
    "       'sensor_measurement20', 'sensor_measurement21']\n",
    "\n",
    "# Plot feature importances\n",
    "for result in results:\n",
    "    model_name = result['Model']\n",
    "    feature_importances = result['Feature_Importances']\n",
    "    \n",
    "    if feature_importances is not None:\n",
    "        plt.figure(figsize=(10, 6))  # Adjust the figure size if needed\n",
    "        plt.bar(range(len(feature_importances)), feature_importances)\n",
    "        plt.xlabel('Feature')\n",
    "        plt.ylabel('Feature Importance')\n",
    "        plt.title(f'Feature Importances for {model_name}')\n",
    "        plt.xticks(range(len(feature_importances)), feature_names, rotation='vertical')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Annotate each bar with the importance value\n",
    "        for i, imp in enumerate(feature_importances):\n",
    "            plt.text(i, imp + 0.01, f'{imp:.4f}', ha='center', va='bottom')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40263ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(test1)\n",
    "test_prediction1 = np.round(model.predict(test1))\n",
    "test1[\"Predicticted_RUL\"] = test_prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[test1['engine_number'] == 2][['engine_number', 'time_cycles', 'Predicticted_RUL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1[train1['engine_number'] == 2][['engine_number', 'time_cycles', 'RUL']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc4ecd",
   "metadata": {},
   "source": [
    "# Overfitting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d29ad",
   "metadata": {},
   "source": [
    "# Selecting only top5 feature according to XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14dd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_top5 = X[['engine_number', 'time_cycles','sensor_measurement4','sensor_measurement11','sensor_measurement12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_top5, X_test_top5, y_train, y_test = train_test_split(X_top5, y, test_size = 0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400efec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_top5, y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_test_top5)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2_square = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Check feature importances (for models that support it)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = model.feature_importances_\n",
    "    else:\n",
    "        feature_importances = None\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2_square,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88923f4d",
   "metadata": {},
   "source": [
    "### According to above info XGBRegressor is best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f71f4",
   "metadata": {},
   "source": [
    "# Predict RUL for our test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d06368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 features\n",
    "test1 = test1[['engine_number', 'time_cycles','sensor_measurement4','sensor_measurement11','sensor_measurement12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X_train_top5, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = np.round(model.predict(test1))\n",
    "test1[\"Predicticted_RUL\"] = test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[test1['engine_number'] == 2][['engine_number', 'time_cycles', 'Predicticted_RUL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1[train1['engine_number'] == 2][['engine_number', 'time_cycles', 'RUL']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0270aa71",
   "metadata": {},
   "source": [
    "# Model is overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690c292",
   "metadata": {},
   "source": [
    "***************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17749be4",
   "metadata": {},
   "source": [
    "# Complete CleanedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57942840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('CleanedData/trainset_clean.csv')\n",
    "df_test = pd.read_csv('CleanedData/testset_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent and dependent feature\n",
    "feature = df_train.drop(columns=['RUL','zone'],axis=1)\n",
    "target = df_train['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa048c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature,target , test_size = 0.2 , random_state=42)\n",
    "\n",
    "###\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2_square = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2_square,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_predicton = np.round(model.predict(df_test))\n",
    "df_test['Predicted_RUL'] = y_predicton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64525646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test['engine_number'] == 100][['engine_number', 'time_cycles', 'Predicted_RUL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f72174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['engine_number'] == 100][['engine_number', 'time_cycles', 'RUL']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c83b58",
   "metadata": {},
   "source": [
    "# Model is Generalized\n",
    "### Save into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('PredictedRUL/PredictedRUL_Complete_test.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df027b39",
   "metadata": {},
   "source": [
    "***************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbb41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('RawData/Train1_raw.csv')\n",
    "test1 = pd.read_csv('RawData/Test1_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Train1 with complete train dataset feature\n",
    "train1_top_feature = train1[['engine_number', 'time_cycles', 'op_setting_1', 'op_setting_3',\n",
    "       'sensor_measurement8', 'sensor_measurement14', 'sensor_measurement16']]\n",
    "test1_top_feature = test1[['engine_number', 'time_cycles', 'op_setting_1', 'op_setting_3',\n",
    "       'sensor_measurement8', 'sensor_measurement14', 'sensor_measurement16']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470227ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding RUL(Remaining Useful Life)\n",
    "def categorize_zone(time_cycles, max_time_cycle):\n",
    "    time_percent = time_cycles / max_time_cycle\n",
    "    if time_percent <= 0.5:  \n",
    "        return \"Safe Zone\"\n",
    "    elif time_percent <= 0.8:\n",
    "        return \"Moderate Zone\"\n",
    "    else:\n",
    "        return \"Dangerous\"\n",
    "\n",
    "def add_zones_rul_column(df):\n",
    "    train_grouped_by_unit = df.groupby(by='engine_number') \n",
    "    max_time_cycles = train_grouped_by_unit['time_cycles'].max() \n",
    "    merged = df.merge(max_time_cycles.to_frame(name='max_time_cycle'), left_on='engine_number',right_index=True)\n",
    "    \n",
    "    merged[\"RUL\"] = merged[\"max_time_cycle\"] - merged['time_cycles']\n",
    "    \n",
    "    merged[\"zone\"] = merged.apply(lambda row: categorize_zone(row['time_cycles'], row['max_time_cycle']), axis=1)\n",
    "    \n",
    "    merged = merged.drop(\"max_time_cycle\", axis=1) \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_top_feature_with_rul = add_zones_rul_column(train1_top_feature)\n",
    "train1_top_feature_with_rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99149e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent and dependent feature\n",
    "independent = train1_top_feature_with_rul.drop(columns=['RUL','zone'],axis=1)\n",
    "dependent = train1_top_feature_with_rul['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddc831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent,dependent , test_size = 0.2 , random_state=42)\n",
    "\n",
    "###\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2_square = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2_square,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_predicton = np.round(model.predict(test1_top_feature))\n",
    "test1_top_feature['Predicted_RUL'] = y_predicton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ede50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_top_feature[test1_top_feature['engine_number'] == 5][['engine_number', 'time_cycles', 'Predicted_RUL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_top_feature_with_rul[train1_top_feature_with_rul['engine_number'] == 5][['engine_number', 'time_cycles', 'RUL']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d623f46",
   "metadata": {},
   "source": [
    "# Model is over fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449e1d0",
   "metadata": {},
   "source": [
    "#### Now Check Without dropiing anyf eature model is generalized or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ff648",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_with_rul = add_zones_rul_column(train1)\n",
    "train1_with_rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent and dependent feature\n",
    "independent = train1_with_rul.drop(columns=['RUL','zone'],axis=1)\n",
    "dependent = train1_with_rul['RUL']\n",
    "\n",
    "# split into train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent,dependent , test_size = 0.2 , random_state=42)\n",
    "\n",
    "###\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_predicton = np.round(model.predict(test1))\n",
    "test1['Predicted_RUL'] = y_predicton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5859ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[test1['engine_number'] == 5][['engine_number', 'time_cycles', 'Predicted_RUL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c17988",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_with_rul[train1_with_rul['engine_number'] == 5][['engine_number', 'time_cycles', 'RUL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d53e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
